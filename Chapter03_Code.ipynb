{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "Spark_Version:2.0.0<br/>\n",
    "Python_Version:Python 3.5.2 | Anaconda4.1.1(64-bit)<br/>\n",
    "Jupyter_Version:4.2.1</br>\n",
    "System:Ubuntu 16.04 LTS(64-bit)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark_Version: 2.0.0\n",
      "Python_Version: 3.5.2\n",
      "System: Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(\"Spark_Version:\",sc.version)\n",
    "print(\"Python_Version:\",platform.python_version())\n",
    "print(\"System:\",platform.system())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames from RDDs\n",
    "The following code creates an RDD from a list of colors followed by a collection of tuples containing the color name and its length. It creates a DataFrame using the `toDF` method to convert the RDD into a DataFrame. The `toDF` method takes a list of column labels as an optional argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a list of colours\n",
    "colors = ['white', 'green', 'yellow', 'red', 'brown', 'pink']\n",
    "#Distribute a local collection to form an RDD\n",
    "#Apply map function on that RDD to get another RDD containing colour,length tuples\n",
    "color_df = sc.parallelize(colors).map(lambda x: (x,len(x))).toDF(['color', 'length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[color: string, length: bigint]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('color', 'string'), ('length', 'bigint')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| color|length|\n",
      "+------+------+\n",
      "| white|     5|\n",
      "| green|     5|\n",
      "|yellow|     6|\n",
      "|   red|     3|\n",
      "| brown|     5|\n",
      "|  pink|     4|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "color_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames from JSON\n",
    "JavaScript Object Notation, or JSON, is a language-independent, self-describing, lightweight data-exchange format. JSON has become a popular data exchange format and has become ubiquitous. In addition to JavaScript and RESTful interfaces, databases such as MySQL have accepted JSON as a data type and MongoDB stores all data as JSON documents in binary form. Conversion of data to and from JSON is essential for any modern data analysis workflow. The Spark DataFrame API lets developers convert JSON objects into DataFrames and vice versa. Let's have a close look at the following examples for a better understanding:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
